{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt_to_str(path:str)->str:\n",
    "    data = ''\n",
    "    try:\n",
    "        my_file = open(path, \"r\")\n",
    "        data = my_file.read().replace('\\n', ' ')\n",
    "        my_file.close()\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f'error {path}, {e}')\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error c:\\Users\\Andrey\\Documents\\exploration\\document_clustering_spending_tracker\\document_classification\\news_data\\sport\\199.txt, 'utf-8' codec can't decode byte 0xa3 in position 257: invalid start byte\n"
     ]
    }
   ],
   "source": [
    "folder_name = ['business','entertainment','politics','sport','tech']\n",
    "res = {}\n",
    "temp_to_df = []\n",
    "for folder in folder_name:\n",
    "    dir_path = os.path.join(os.getcwd(),'news_data',folder)\n",
    "    res_temp = []\n",
    "    for path in os.listdir(dir_path):\n",
    "        if os.path.isfile(os.path.join(dir_path, path)):\n",
    "            str_res = read_txt_to_str(os.path.join(dir_path,path))\n",
    "            res_temp.append(str_res)\n",
    "            temp_to_df.append([str_res,folder])\n",
    "    res[folder] = res_temp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(temp_to_df,columns=['text','cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Andrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Andrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('wordnet') # for download to this path\n",
    "nltk.download('punkt')\n",
    "nltk.data.path.append('corpora')\n",
    "nltk.data.path.append('tokenizers')\n",
    "\n",
    "try:\n",
    "    from nltk.stem.wordnet import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    def lemmatize(text : str) -> str:\n",
    "        return lemmatizer.lemmatize(text)\n",
    "except Exception as e:\n",
    "    print(f'failed to load WordNetLemmatizer {e}')\n",
    "    def lemmatize(text : str) -> str:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from nltk.tokenize import word_tokenize\n",
    "except Exception as e:\n",
    "    print(f'error load nltk tokenize {e}')\n",
    "    def word_tokenize(text:str)->list:\n",
    "        return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text:str)->str:\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "def list_to_text(l:list)->str:\n",
    "    return ' '.join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text : str) -> str:\n",
    "    res = []\n",
    "    text = text_cleaning(text)\n",
    "    list_text = word_tokenize(text)\n",
    "    for word in list_text:\n",
    "        res.append(lemmatize(word))\n",
    "    return list_to_text(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_cleaned'] = df['text'].apply(lambda x:preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(text:str)->int:\n",
    "    return len(text.split())\n",
    "\n",
    "df['max_len'] = df['text_cleaned'].apply(lambda x:get_max_len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mapping = {}\n",
    "for row_text in df['text_cleaned']:\n",
    "    for word in row_text.split():\n",
    "        if word not in unique_mapping:\n",
    "            unique_mapping[word] = 1\n",
    "        else:\n",
    "            unique_mapping[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28095"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cat</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>max_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
       "      <td>business</td>\n",
       "      <td>ad sale boost time warner profit quarterly pro...</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech  The dollar h...</td>\n",
       "      <td>business</td>\n",
       "      <td>dollar gain on greenspan speech the dollar ha ...</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim  The owners ...</td>\n",
       "      <td>business</td>\n",
       "      <td>yukos unit buyer face loan claim the owner of ...</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits  British Air...</td>\n",
       "      <td>business</td>\n",
       "      <td>high fuel price hit ba profit british airway h...</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq  Shares in U...</td>\n",
       "      <td>business</td>\n",
       "      <td>pernod takeover talk lift domecq share in uk d...</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       cat  \\\n",
       "0  Ad sales boost Time Warner profit  Quarterly p...  business   \n",
       "1  Dollar gains on Greenspan speech  The dollar h...  business   \n",
       "2  Yukos unit buyer faces loan claim  The owners ...  business   \n",
       "3  High fuel prices hit BA's profits  British Air...  business   \n",
       "4  Pernod takeover talk lifts Domecq  Shares in U...  business   \n",
       "\n",
       "                                        text_cleaned  max_len  \n",
       "0  ad sale boost time warner profit quarterly pro...      399  \n",
       "1  dollar gain on greenspan speech the dollar ha ...      377  \n",
       "2  yukos unit buyer face loan claim the owner of ...      260  \n",
       "3  high fuel price hit ba profit british airway h...      383  \n",
       "4  pernod takeover talk lift domecq share in uk d...      252  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rakamin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
