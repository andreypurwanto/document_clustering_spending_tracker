{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Dataframe Manipulation library\n",
    "import numpy as np #Data Manipulation library\n",
    "\n",
    "#sklearn modules for Feature Extraction & Modelling\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#Libraries for Plotting \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import joblib\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_json(os.path.join(os.getcwd(),'data','News_Category_Dataset_v3.json'), lines=True)\n",
    "except Exception as e:\n",
    "    df = pd.read_csv(os.path.join(os.getcwd(),'data','category_news_selected.csv'))\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_combine'] = df['headline'] + \" \" + df['short_description']\n",
    "df = df[['text_combine','category']]\n",
    "df_train = df.iloc[:int(len(df)*0.8)]\n",
    "df_test = df.iloc[int(len(df)*0.8):len(df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_combine</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>COMEDY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maury Wills, Base-Stealing Shortstop For Dodge...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‘Beautiful And Sad At The Same Time’: Ukrainia...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Las Vegas Aces Win First WNBA Title, Chelsea G...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>James Cameron Says He 'Clashed' With Studio Be...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text_combine       category\n",
       "0  23 Of The Funniest Tweets About Cats And Dogs ...         COMEDY\n",
       "1  Maury Wills, Base-Stealing Shortstop For Dodge...         SPORTS\n",
       "4  ‘Beautiful And Sad At The Same Time’: Ukrainia...       POLITICS\n",
       "5  Las Vegas Aces Win First WNBA Title, Chelsea G...         SPORTS\n",
       "6  James Cameron Says He 'Clashed' With Studio Be...  ENTERTAINMENT"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Andrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Andrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('wordnet') # for download to this path\n",
    "nltk.download('punkt')\n",
    "nltk.data.path.append('corpora')\n",
    "nltk.data.path.append('tokenizers')\n",
    "\n",
    "try:\n",
    "    from nltk.stem.wordnet import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    def lemmatize(text : str) -> str:\n",
    "        return lemmatizer.lemmatize(text)\n",
    "except Exception as e:\n",
    "    print(f'failed to load WordNetLemmatizer {e}')\n",
    "    def lemmatize(text : str) -> str:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from nltk.tokenize import word_tokenize\n",
    "except Exception as e:\n",
    "    print(f'error load nltk tokenize {e}')\n",
    "    def word_tokenize(text:str)->list:\n",
    "        return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text:str)->str:\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "def list_to_text(l:list)->str:\n",
    "    return ' '.join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text : str) -> str:\n",
    "    res = []\n",
    "    text = text_cleaning(text)\n",
    "    list_text = word_tokenize(text)\n",
    "    for word in list_text:\n",
    "        res.append(lemmatize(word))\n",
    "    return list_to_text(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'over million american roll up sleeve for omicrontargeted covid booster health expert said it is too early to predict whether demand would match up with the million dos of the new booster the u ordered for the fall'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text('Over 4 Million Americans Roll Up Sleeves For Omicron-Targeted COVID Boosters Health experts said it is too early to predict whether demand would match up with the 171 million doses of the new boosters the U.S. ordered for the fall.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrey\\AppData\\Local\\Temp\\ipykernel_5112\\4197579947.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['text_combine_cleaned'] = df_train['text_combine'].apply(lambda x:preprocess_text(x))\n"
     ]
    }
   ],
   "source": [
    "df_train['text_combine_cleaned'] = df_train['text_combine'].apply(lambda x:preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(os.path.join(os.getcwd(),'data','local_train_data_clean.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_combine</th>\n",
       "      <th>category</th>\n",
       "      <th>text_combine_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>of the funniest tweet about cat and dog this w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maury Wills, Base-Stealing Shortstop For Dodge...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>maury will basestealing shortstop for dodger d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‘Beautiful And Sad At The Same Time’: Ukrainia...</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>‘ beautiful and sad at the same time ’ ukraini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Las Vegas Aces Win First WNBA Title, Chelsea G...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>la vega ace win first wnba title chelsea gray ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>James Cameron Says He 'Clashed' With Studio Be...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>james cameron say he clashed with studio befor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text_combine       category  \\\n",
       "0  23 Of The Funniest Tweets About Cats And Dogs ...         COMEDY   \n",
       "1  Maury Wills, Base-Stealing Shortstop For Dodge...         SPORTS   \n",
       "4  ‘Beautiful And Sad At The Same Time’: Ukrainia...       POLITICS   \n",
       "5  Las Vegas Aces Win First WNBA Title, Chelsea G...         SPORTS   \n",
       "6  James Cameron Says He 'Clashed' With Studio Be...  ENTERTAINMENT   \n",
       "\n",
       "                                text_combine_cleaned  \n",
       "0  of the funniest tweet about cat and dog this w...  \n",
       "1  maury will basestealing shortstop for dodger d...  \n",
       "4  ‘ beautiful and sad at the same time ’ ukraini...  \n",
       "5  la vega ace win first wnba title chelsea gray ...  \n",
       "6  james cameron say he clashed with studio befor...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68642, 3)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "petrol cars cheaper diesel cars\n",
      "diesel cheaper petrol\n"
     ]
    }
   ],
   "source": [
    "# We will check with different data and use this method again in training\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "doc1=\"petrol cars cheaper diesel cars\"\n",
    "doc2=\"diesel cheaper petrol\"\n",
    "doc_corpus=[doc1,doc2]\n",
    "for x in doc_corpus:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter((doc1+' '+doc2).split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_temp = list(counter.keys())\n",
    "res_temp = []\n",
    "count = 0\n",
    "for sentence in doc_corpus:\n",
    "    res_temp.append([])\n",
    "    counter_temp = Counter(sentence.split())\n",
    "    for key in counter:\n",
    "        if key in counter_temp:\n",
    "            res_temp[count].append(counter_temp[key])\n",
    "        else:\n",
    "            res_temp[count].append(0)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petrol</th>\n",
       "      <th>cars</th>\n",
       "      <th>cheaper</th>\n",
       "      <th>diesel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   petrol  cars  cheaper  diesel\n",
       "0       1     2        1       1\n",
       "1       1     0        1       1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(res_temp,columns=columns_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names n ['cars' 'cheaper' 'diesel' 'petrol']\n"
     ]
    }
   ],
   "source": [
    "vec=TfidfVectorizer(stop_words='english')\n",
    "vec.fit(doc_corpus)\n",
    "matrix = vec.transform(doc_corpus)\n",
    "print(\"Feature Names n\",vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.85135433 0.30287281 0.30287281 0.30287281]\n",
      " [0.         0.57735027 0.57735027 0.57735027]]\n"
     ]
    }
   ],
   "source": [
    "print(matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = Total number of documents available\n",
    "# t = term for which idf value has to be calculated\n",
    "# df(t) = Number of documents in which the term t appears\n",
    "\n",
    "# idf(t) = log e [ (1+n) / ( 1 + df(t) ) ] + 1\n",
    "\n",
    "# Here n=2 (no. Of docs)\n",
    "\n",
    "# for d1\n",
    "\n",
    "# idf(“cars”) = log e (3/2) +1 => 1.405465083\n",
    "# idf(“cheaper”) = log e (3/3) + 1 => 1\n",
    "# idf(“diesel”) = log e (3/3) + 1 => 1\n",
    "# idf(“petrol”) = log e (3/3) + 1 => 1\n",
    "\n",
    "# tf idf For d1\n",
    "\n",
    "# tf-idf(“cars”) = tf(“cars”) x idf (“cars”) = 2 x 1.405465083 => 2.810930165\n",
    "# tf-idf(“cheaper”) = tf(“cheaper”) x idf (“cheaper”) = 1 x 1 => 1\n",
    "# tf-idf(“diesel”) = tf(“diesel”) x idf (“diesel”) = 1×1 => 1\n",
    "# tf-idf(“petrol”) = tf(“petrol”) x idf (“petrol”) = 1×1 => 1\n",
    "\n",
    "# normalize value d1\n",
    "\n",
    "# 2.810930165 / sqrt( 2.810930165^2 + 1^2 + 1^2 + 1^2) => 0.851354321\n",
    "# 1 / sqrt( 2.810930165^2 + 1^2 + 1^2 + 1^2) =>  0.302872811\n",
    "# 1 / sqrt( 2.810930165^2 + 1^2 + 1^2 + 1^2) => 0.302872811\n",
    "# 1 / sqrt( 2.810930165^2 + 1^2 + 1^2 + 1^2) => 0.302872811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.transform(['cars cars car']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d1\n",
    "\n",
    "# idf(“cars”) = log e (3/2) +1 => 1.405465083\n",
    "\n",
    "# tf idf For d1\n",
    "\n",
    "# tf-idf(“cars”) = tf(“cars”) x idf (“cars”) = 2 x 1.405465083 => 2.810930165\n",
    "\n",
    "# normalize value d1\n",
    "\n",
    "# 2.810930165 / sqrt( 2.810930165^2) => 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "from time import time\n",
    "from gensim import utils\n",
    "import multiprocessing\n",
    "\n",
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        for line in df_train['text_combine_cleaned']:\n",
    "            yield utils.simple_preprocess(line)\n",
    "\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = MyCorpus()\n",
    "model_w2v = gensim.models.Word2Vec(workers=cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.04 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "model_w2v.build_vocab(sentences, progress_per=10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.57 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "model_w2v.train(sentences, total_examples=model_w2v.corpus_count, epochs=10, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12731877,  0.7004593 , -0.38843068, -1.4380304 ,  0.1127122 ,\n",
       "       -1.7582327 ,  0.9973596 , -0.92865074,  2.1139367 , -1.031768  ,\n",
       "        0.07705914,  1.6947329 , -1.719214  , -0.62598634, -0.6141067 ,\n",
       "        1.7429329 ,  2.257469  , -0.40298876,  1.7815447 ,  3.1612105 ,\n",
       "       -1.7909504 ,  3.5075374 ,  0.8425165 , -1.4787859 ,  2.941333  ,\n",
       "        0.6435059 , -0.4635814 , -0.86058694, -2.829369  , -0.0326717 ,\n",
       "        0.85002637,  0.67172664, -1.8341613 ,  0.2758235 , -1.2075851 ,\n",
       "       -0.2550808 , -1.7684009 ,  0.9830752 , -0.6362522 , -0.9478137 ,\n",
       "        0.48691228,  1.582207  , -2.1133778 ,  0.08790875, -0.30527428,\n",
       "       -0.666891  , -0.61124134,  1.7523847 ,  1.5287738 , -0.03888857,\n",
       "        1.4808089 ,  0.36731514, -0.5734472 ,  0.05290028, -1.0429794 ,\n",
       "        1.8851348 ,  0.3507833 ,  0.05946754, -0.9343644 ,  0.21388546,\n",
       "        1.1243306 , -0.10084579, -2.9172482 , -0.13404709,  0.161958  ,\n",
       "        0.81922656, -1.3036067 , -1.5698212 , -0.99485475,  0.78122824,\n",
       "       -0.53939325, -0.8744184 ,  0.24563172, -2.4966183 ,  1.7918074 ,\n",
       "       -0.22367679, -0.7687863 , -2.0579927 , -2.975451  , -0.7472013 ,\n",
       "       -0.42181158,  2.253227  ,  0.33328483, -3.4872015 , -2.0148025 ,\n",
       "        1.6017035 ,  2.2139575 ,  1.1290838 , -1.1527915 , -1.3496631 ,\n",
       "       -0.28016263,  0.00583468, -0.0605321 , -0.6029297 ,  1.5794412 ,\n",
       "        1.4320698 ,  0.7424231 ,  0.02874962, -0.83470494,  0.01994988],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv['million']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('billion', 0.7381351590156555),\n",
       " ('dollar', 0.6780257225036621),\n",
       " ('percent', 0.6763569116592407),\n",
       " ('thousand', 0.6651930212974548),\n",
       " ('hundred', 0.6272211074829102),\n",
       " ('nearly', 0.601820707321167),\n",
       " ('taxpayer', 0.5976290702819824),\n",
       " ('charity', 0.5879110097885132),\n",
       " ('trillion', 0.5599369406700134),\n",
       " ('hike', 0.551967978477478)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.wv['million']\n",
    "model_w2v.wv.most_similar(positive=[\"million\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39496014"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.similarity(\"million\", 'money')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'europe'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.doesnt_match([\"million\", \"money\", \"europe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(os.getcwd(),'saved_model')):\n",
    "    os.makedirs(os.path.join(os.getcwd(),'saved_model'))\n",
    "\n",
    "if not os.path.exists(os.path.join(os.getcwd(),'saved_model','word2vec')):\n",
    "    os.makedirs(os.path.join(os.getcwd(),'saved_model','word2vec'))\n",
    "\n",
    "model_w2v.save(os.path.join(os.getcwd(),'saved_model','word2vec','gensim-word2vec-model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = gensim.models.Word2Vec.load(os.path.join(os.getcwd(),'saved_model','word2vec','gensim-word2vec-model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('billion', 0.7381351590156555),\n",
       " ('dollar', 0.6780257225036621),\n",
       " ('percent', 0.6763569116592407),\n",
       " ('thousand', 0.6651930212974548),\n",
       " ('hundred', 0.6272211074829102),\n",
       " ('nearly', 0.601820707321167),\n",
       " ('taxpayer', 0.5976290702819824),\n",
       " ('charity', 0.5879110097885132),\n",
       " ('trillion', 0.5599369406700134),\n",
       " ('hike', 0.551967978477478)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.wv.most_similar(positive=[\"million\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_df_train = []\n",
    "count = 0\n",
    "for sentence in df_train['text_combine_cleaned']:\n",
    "    tagged_df_train.append(gensim.models.doc2vec.TaggedDocument(sentence.split(), [count]))\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d2v = gensim.models.doc2vec.Doc2Vec(vector_size=200, min_count=2, epochs=20, workers=cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d2v.build_vocab(tagged_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'million' appeared 1112 times in the training corpus.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Word 'million' appeared {model_d2v.wv.get_vecattr('million', 'count')} times in the training corpus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d2v.train(tagged_df_train, total_examples=model_d2v.corpus_count, epochs=model_d2v.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = model_d2v.infer_vector(df_train['text_combine_cleaned'].iloc[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2339821 , -0.1220803 , -0.09300172,  0.26324868,  0.03976153,\n",
       "       -0.0991462 ,  0.09826183,  0.13130124,  0.1791708 ,  0.2444231 ,\n",
       "        0.09562145, -0.1548553 , -0.05314378,  0.153964  , -0.01433426,\n",
       "       -0.08794248,  0.15181649, -0.15645322,  0.14349115, -0.10716932,\n",
       "        0.12722124, -0.20974667,  0.18901801,  0.04673327, -0.08752485,\n",
       "       -0.09929431,  0.18107665, -0.20287281, -0.08058515,  0.0653967 ,\n",
       "        0.22349824,  0.03104123,  0.37100613,  0.0397216 , -0.0035311 ,\n",
       "        0.14860617,  0.00680171,  0.06424663, -0.09308906, -0.04910458,\n",
       "       -0.13124786, -0.02382417,  0.02896591,  0.0757371 , -0.04795402,\n",
       "       -0.11993109,  0.07988014, -0.03982693, -0.1395995 ,  0.3883583 ,\n",
       "       -0.15365298,  0.2327805 , -0.11685895, -0.0441923 ,  0.2789711 ,\n",
       "       -0.07769088, -0.17566225,  0.14162639, -0.09826218,  0.00123879,\n",
       "       -0.05805755, -0.02212106,  0.0028285 ,  0.01568701, -0.06692484,\n",
       "       -0.04664307,  0.08141559,  0.15464234, -0.03596251, -0.33193982,\n",
       "        0.0077099 , -0.02288222,  0.19612491,  0.1502247 ,  0.13703723,\n",
       "       -0.18340023, -0.0451126 , -0.12625788, -0.41096413, -0.1931916 ,\n",
       "       -0.03369023, -0.0289602 ,  0.1689035 ,  0.12042848, -0.08321226,\n",
       "       -0.2497839 , -0.04757161,  0.15115777, -0.05633913, -0.01854067,\n",
       "       -0.08404803,  0.17807013,  0.0569759 , -0.03241756,  0.10113601,\n",
       "        0.23786469, -0.20768537, -0.2515771 ,  0.21665505,  0.09684221,\n",
       "       -0.18900484, -0.06619781,  0.0252355 , -0.07368057,  0.04901964,\n",
       "        0.09402068,  0.11718438, -0.06821784, -0.11181995, -0.18007442,\n",
       "       -0.1391226 , -0.01819337, -0.01903845, -0.07399759,  0.14307414,\n",
       "       -0.157631  , -0.1551702 , -0.10307541,  0.0807837 , -0.15928736,\n",
       "        0.06417937, -0.01523899,  0.17271605, -0.09982532,  0.03914139,\n",
       "       -0.10158713, -0.18350266, -0.16877888, -0.16682921, -0.02770431,\n",
       "        0.11794876,  0.1272233 ,  0.23831731, -0.17131579,  0.18397039,\n",
       "        0.19472452, -0.223591  , -0.14900349,  0.00268818, -0.25069648,\n",
       "       -0.08958656, -0.23195307,  0.10457253, -0.05916525,  0.04521449,\n",
       "        0.17666501,  0.06207605, -0.1272199 , -0.06497481, -0.03852458,\n",
       "        0.306099  ,  0.07117634,  0.07726362,  0.16762505, -0.3298743 ,\n",
       "        0.11559505,  0.18981068,  0.07532425,  0.05059807, -0.12846221,\n",
       "       -0.01907894,  0.03251241, -0.2771647 , -0.04460695,  0.06600823,\n",
       "        0.19902983,  0.06186898, -0.3470289 ,  0.30137962, -0.18609011,\n",
       "       -0.22448476,  0.38756248,  0.04007909, -0.00916067, -0.02814436,\n",
       "        0.06744875,  0.20010386, -0.00692513, -0.02004608, -0.10569616,\n",
       "        0.02622617,  0.09964781,  0.05429982,  0.05081221, -0.0841982 ,\n",
       "        0.1052955 ,  0.03492019,  0.01024829,  0.24472025, -0.07172641,\n",
       "        0.13231009,  0.28120437,  0.23729351,  0.09260956,  0.12495138,\n",
       "       -0.15185842, -0.09151176,  0.12244521, -0.1512102 ,  0.1234794 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(tagged_df_train)):\n",
    "    if doc_id == 4:\n",
    "        inferred_vector = model_d2v.infer_vector(tagged_df_train[doc_id].words)\n",
    "        sims = model_d2v.dv.most_similar([inferred_vector], topn=len(model_d2v.dv))\n",
    "        rank = [docid for docid, sim in sims].index(doc_id)\n",
    "        ranks.append(rank)\n",
    "\n",
    "        second_ranks.append(sims[1])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_combine</th>\n",
       "      <th>category</th>\n",
       "      <th>text_combine_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>of the funniest tweet about cat and dog this w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maury Wills, Base-Stealing Shortstop For Dodge...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>maury will basestealing shortstop for dodger d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‘Beautiful And Sad At The Same Time’: Ukrainia...</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>‘ beautiful and sad at the same time ’ ukraini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Las Vegas Aces Win First WNBA Title, Chelsea G...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>la vega ace win first wnba title chelsea gray ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>James Cameron Says He 'Clashed' With Studio Be...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>james cameron say he clashed with studio befor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text_combine       category  \\\n",
       "0  23 Of The Funniest Tweets About Cats And Dogs ...         COMEDY   \n",
       "1  Maury Wills, Base-Stealing Shortstop For Dodge...         SPORTS   \n",
       "4  ‘Beautiful And Sad At The Same Time’: Ukrainia...       POLITICS   \n",
       "5  Las Vegas Aces Win First WNBA Title, Chelsea G...         SPORTS   \n",
       "6  James Cameron Says He 'Clashed' With Studio Be...  ENTERTAINMENT   \n",
       "\n",
       "                                text_combine_cleaned  \n",
       "0  of the funniest tweet about cat and dog this w...  \n",
       "1  maury will basestealing shortstop for dodger d...  \n",
       "4  ‘ beautiful and sad at the same time ’ ukraini...  \n",
       "5  la vega ace win first wnba title chelsea gray ...  \n",
       "6  james cameron say he clashed with studio befor...  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTERTAINMENT Document (4): «james cameron say he clashed with studio before avatar release the avatar director said aspect of his movie are still competitive with everything that ’ s out there these day»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec<dm/m,d200,n5,w5,mc2,s0.001,t7>:\n",
      "\n",
      "SPORTS MOST (21919, 0.5122023820877075): «trump say he shocked by all the meanness out there the president admits the combativeness of his white house could be my fault»\n",
      "\n",
      "POLITICS SECOND-MOST (45244, 0.4905182719230652): «this note left in robert griffin iii ’ s locker sure seems like a clue to his future it certainly look like rgiii is ready to get out of dc»\n",
      "\n",
      "ENTERTAINMENT MEDIAN (37694, 0.1514284461736679): «before scotus blockade this gop senator wanted obama to hurry up and fill federal vacancy ron johnson said last year that president should fill vacancy within day»\n",
      "\n",
      "COMEDY LEAST (40922, -0.22145676612854004): «the army tell it soldier to get some sleep it leader are looking to improve troop performance and reduce death»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('{} Document ({}): «{}»\\n'.format(df_train['category'].iloc[doc_id], doc_id, ' '.join(tagged_df_train[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model_d2v)\n",
    "for label, index in [('MOST', 1), ('SECOND-MOST', 2), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s %s: «%s»\\n' % (df_train['category'].iloc[index] ,label, sims[index], ' '.join(tagged_df_train[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train.iloc[0]['text_combine'])\n",
    "# print(df_train.iloc[58388]['text_combine'])\n",
    "# print(df_train.iloc[26343]['text_combine'])\n",
    "# print(df_train.iloc[83245]['text_combine'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using tf idf vectorizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_used = ('POLITICS', 'ENTERTAINMENT', 'WELLNESS', 'HEALTHY LIVING', 'QUEER VOICES', 'TRAVEL', 'BUSINESS', 'SPORTS', 'COMEDY')\n",
    "df_train_selected = df_train[df_train['category'].isin(category_used)][['text_combine_cleaned','category']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_col = df_train_selected['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_col = {}\n",
    "\n",
    "count = 0\n",
    "for x in unique_col:\n",
    "    map_col[count] = x\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_category_id(x, unique_col):\n",
    "    count = 0\n",
    "    for col in unique_col:\n",
    "        if str(x) == str(col):\n",
    "            return count\n",
    "        count+=1 \n",
    "\n",
    "df_train_selected['category_id'] = df_train_selected['category'].apply(lambda x : to_category_id(x,unique_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, max_features=10000,\n",
    "                        stop_words='english')\n",
    "\n",
    "features = tfidf.fit_transform(df_train_selected['text_combine_cleaned']).toarray()\n",
    "\n",
    "labels = df_train_selected['category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andrey\\miniconda3\\envs\\rakamin2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Andrey\\miniconda3\\envs\\rakamin2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Andrey\\miniconda3\\envs\\rakamin2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "# 5 Cross-validation\n",
    "CV = 3\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>fold_idx</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.432499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1</td>\n",
       "      <td>0.432455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>0.432474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0</td>\n",
       "      <td>0.672698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>1</td>\n",
       "      <td>0.703422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>2</td>\n",
       "      <td>0.699607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0</td>\n",
       "      <td>0.740964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>1</td>\n",
       "      <td>0.766050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>2</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_name  fold_idx  accuracy\n",
       "0  RandomForestClassifier         0  0.432499\n",
       "1  RandomForestClassifier         1  0.432455\n",
       "2  RandomForestClassifier         2  0.432474\n",
       "3           MultinomialNB         0  0.672698\n",
       "4           MultinomialNB         1  0.703422\n",
       "5           MultinomialNB         2  0.699607\n",
       "6      LogisticRegression         0  0.740964\n",
       "7      LogisticRegression         1  0.766050\n",
       "8      LogisticRegression         2  0.737500"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_combine_cleaned</th>\n",
       "      <th>category</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>of the funniest tweet about cat and dog this w...</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maury will basestealing shortstop for dodger d...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‘ beautiful and sad at the same time ’ ukraini...</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>la vega ace win first wnba title chelsea gray ...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>james cameron say he clashed with studio befor...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text_combine_cleaned       category  \\\n",
       "0  of the funniest tweet about cat and dog this w...         COMEDY   \n",
       "1  maury will basestealing shortstop for dodger d...         SPORTS   \n",
       "2  ‘ beautiful and sad at the same time ’ ukraini...       POLITICS   \n",
       "3  la vega ace win first wnba title chelsea gray ...         SPORTS   \n",
       "4  james cameron say he clashed with studio befor...  ENTERTAINMENT   \n",
       "\n",
       "   category_id  \n",
       "0            0  \n",
       "1            1  \n",
       "2            2  \n",
       "3            1  \n",
       "4            3  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_selected.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andrey\\miniconda3\\envs\\rakamin2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X = df_train_selected['text_combine_cleaned'] # Collection of documents\n",
    "y = df_train_selected['category'] # Target or the labels we want to predict (i.e., the 13 different complaints of products)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state = 0)\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,\n",
    "                        ngram_range=(1, 2), \n",
    "                        stop_words='english')\n",
    "\n",
    "fitted_vectorizer = tfidf.fit(X_train)\n",
    "tfidf_vectorizer_vectors = fitted_vectorizer.transform(X_train)\n",
    "\n",
    "model = LogisticRegression().fit(tfidf_vectorizer_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HEALTHY LIVING'], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ['eat apple loss weight']\n",
    "model.predict(fitted_vectorizer.transform(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HEALTHY LIVING'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ['apple inc loss weight']\n",
    "model.predict(fitted_vectorizer.transform(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "      BUSINESS       0.78      0.56      0.66       870\n",
      "        COMEDY       0.73      0.42      0.53       899\n",
      " ENTERTAINMENT       0.78      0.86      0.81      3165\n",
      "HEALTHY LIVING       0.52      0.58      0.55      1237\n",
      "      POLITICS       0.84      0.96      0.89      7408\n",
      "  QUEER VOICES       0.85      0.62      0.72       988\n",
      "        SPORTS       0.86      0.67      0.75       844\n",
      "        TRAVEL       0.87      0.75      0.80       875\n",
      "      WELLNESS       0.49      0.32      0.39       875\n",
      "\n",
      "      accuracy                           0.79     17161\n",
      "     macro avg       0.75      0.64      0.68     17161\n",
      "  weighted avg       0.78      0.79      0.78     17161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(fitted_vectorizer.transform(X_test))\n",
    "print(classification_report(y_test, y_pred, target_names=model.classes_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using doc2vec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select model with cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_df_train = []\n",
    "count = 0\n",
    "for sentence in df_train_selected['text_combine_cleaned']:\n",
    "    tagged_df_train.append(gensim.models.doc2vec.TaggedDocument(sentence.split(), [count]))\n",
    "    count+=1\n",
    "\n",
    "model_d2v = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=10, workers=cores-1)\n",
    "model_d2v.build_vocab(tagged_df_train)\n",
    "model_d2v.train(tagged_df_train, total_examples=model_d2v.corpus_count, epochs=model_d2v.epochs)\n",
    "vector = model_d2v.infer_vector(df_train_selected['text_combine_cleaned'].iloc[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "res_zero = model_d2v.infer_vector(df_train_selected['text_combine_cleaned'].iloc[0].split())\n",
    "init_array = np.reshape(res_zero, (-1, 50))\n",
    "count = 0\n",
    "for word in df_train_selected['text_combine_cleaned']:\n",
    "    # print(count)\n",
    "    if count>0:\n",
    "        res_ = model_d2v.infer_vector(word.split())\n",
    "        init_array = np.vstack((init_array, res_))\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68642"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_selected['text_combine_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train_selected['category'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(init_array, y, \n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state = 0)\n",
    "labels = df_train_selected['category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andrey\\miniconda3\\envs\\rakamin2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Andrey\\miniconda3\\envs\\rakamin2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Andrey\\miniconda3\\envs\\rakamin2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "# 5 Cross-validation\n",
    "CV = 3\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>fold_idx</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.432499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1</td>\n",
       "      <td>0.432455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>0.432474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0</td>\n",
       "      <td>0.672698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>1</td>\n",
       "      <td>0.703422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>2</td>\n",
       "      <td>0.699607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0</td>\n",
       "      <td>0.740964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>1</td>\n",
       "      <td>0.766050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>2</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_name  fold_idx  accuracy\n",
       "0  RandomForestClassifier         0  0.432499\n",
       "1  RandomForestClassifier         1  0.432455\n",
       "2  RandomForestClassifier         2  0.432474\n",
       "3           MultinomialNB         0  0.672698\n",
       "4           MultinomialNB         1  0.703422\n",
       "5           MultinomialNB         2  0.699607\n",
       "6      LogisticRegression         0  0.740964\n",
       "7      LogisticRegression         1  0.766050\n",
       "8      LogisticRegression         2  0.737500"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_combine_cleaned</th>\n",
       "      <th>category</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>of the funniest tweet about cat and dog this w...</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maury will basestealing shortstop for dodger d...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‘ beautiful and sad at the same time ’ ukraini...</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>la vega ace win first wnba title chelsea gray ...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>james cameron say he clashed with studio befor...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text_combine_cleaned       category  \\\n",
       "0  of the funniest tweet about cat and dog this w...         COMEDY   \n",
       "1  maury will basestealing shortstop for dodger d...         SPORTS   \n",
       "2  ‘ beautiful and sad at the same time ’ ukraini...       POLITICS   \n",
       "3  la vega ace win first wnba title chelsea gray ...         SPORTS   \n",
       "4  james cameron say he clashed with studio befor...  ENTERTAINMENT   \n",
       "\n",
       "   category_id  \n",
       "0            0  \n",
       "1            1  \n",
       "2            2  \n",
       "3            1  \n",
       "4            3  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train_selected['category'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train_selected['text_combine_cleaned'], y, \n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state = 0)\n",
    "labels = df_train_selected['category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_df_train = []\n",
    "count = 0\n",
    "for sentence in X_train:\n",
    "    tagged_df_train.append(gensim.models.doc2vec.TaggedDocument(sentence.split(), [count]))\n",
    "    count+=1\n",
    "\n",
    "model_d2v = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=10, workers=cores-1)\n",
    "model_d2v.build_vocab(tagged_df_train)\n",
    "model_d2v.train(tagged_df_train, total_examples=model_d2v.corpus_count, epochs=model_d2v.epochs)\n",
    "vector = model_d2v.infer_vector(df_train_selected['text_combine_cleaned'].iloc[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "res_zero = model_d2v.infer_vector(X_train.iloc[0].split())\n",
    "X_train_array = np.reshape(res_zero, (-1, 50))\n",
    "count = 0\n",
    "for words in X_train:\n",
    "    if count>0:\n",
    "        res_ = model_d2v.infer_vector(words.split())\n",
    "        X_train_array = np.vstack((X_train_array, res_))\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andrey\\miniconda3\\envs\\rakamin2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression().fit(X_train_array, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "res_zero = model_d2v.infer_vector(X_test.iloc[0].split())\n",
    "X_test_array = np.reshape(res_zero, (-1, 50))\n",
    "count = 0\n",
    "for words in X_test:\n",
    "    if count>0:\n",
    "        res_ = model_d2v.infer_vector(words.split())\n",
    "        X_test_array = np.vstack((X_test_array, res_))\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "      BUSINESS       0.57      0.29      0.38       870\n",
      "        COMEDY       0.29      0.08      0.12       899\n",
      " ENTERTAINMENT       0.61      0.75      0.67      3165\n",
      "HEALTHY LIVING       0.39      0.37      0.38      1237\n",
      "      POLITICS       0.72      0.89      0.80      7408\n",
      "  QUEER VOICES       0.55      0.33      0.41       988\n",
      "        SPORTS       0.60      0.33      0.43       844\n",
      "        TRAVEL       0.66      0.61      0.63       875\n",
      "      WELLNESS       0.41      0.19      0.26       875\n",
      "\n",
      "      accuracy                           0.64     17161\n",
      "     macro avg       0.53      0.43      0.45     17161\n",
      "  weighted avg       0.61      0.64      0.61     17161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_array)\n",
    "print(classification_report(y_test, y_pred, target_names=model.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rakamin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
